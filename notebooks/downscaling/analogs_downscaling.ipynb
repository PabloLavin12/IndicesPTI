{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b3e6ee-b9ce-4c85-b44c-6d6f3f37f398",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a25875-8d54-46bb-b854-4004aa2502bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "Loading required package: transformeR\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _______   ____  ___________________  __  ________ \n",
      "   / ___/ /  / /  |/  / __  /_  __/ __/ / / / / __  / \n",
      "  / /  / /  / / /|_/ / /_/ / / / / __/ / /_/ / /_/_/  \n",
      " / /__/ /__/ / /  / / __  / / / / /__ /___  / / \\ \\ \n",
      " \\___/____/_/_/  /_/_/ /_/ /_/  \\___/    /_/\\/   \\_\\ \n",
      " \n",
      "      github.com/SantanderMetGroup/climate4R\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transformeR version 2.2.2 (2023-10-26) is loaded\n",
      "\n",
      "WARNING: Your current version of transformeR (v2.2.2) is not up-to-date\n",
      "\n",
      "Get the latest stable version (2.2.3) using <devtools::install_github('SantanderMetGroup/transformeR')>\n",
      "\n",
      "Please see 'citation(\"transformeR\")' to cite this package.\n",
      "\n",
      "visualizeR version 1.6.4 (2023-10-26) is loaded\n",
      "\n",
      "Please see 'citation(\"visualizeR\")' to cite this package.\n",
      "\n",
      "downscaleR version 3.3.4 (2023-06-22) is loaded\n",
      "\n",
      "Please use 'citation(\"downscaleR\")' to cite this package.\n",
      "\n",
      "Loading required package: SpecsVerification\n",
      "\n",
      "\n",
      "Attaching package: ‘easyVerification’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:SpecsVerification’:\n",
      "\n",
      "    EnsCorr\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(grid)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "library(visualizeR)\n",
    "library(downscaleR)\n",
    "library(transformeR)\n",
    "library(RColorBrewer)\n",
    "library(easyVerification)\n",
    "\n",
    "color = colorRampPalette(rev(brewer.pal(n = 9, \"RdYlBu\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73581ae6-77d6-4904-b00f-101b5d65526f",
   "metadata": {},
   "source": [
    "El primer paso es preparar los datos de nuestro predictando, la temperatura media (tas) de ERA5-Land a 0.1º, y los datos de nuestros predictores, la temperatura media (tas) y la presión en superficie (sp) de ERA5 a 0.25º, pero habiendo escalado los datos a la resolución de nuestro modelo del ECMWF, en este caso 1º.\n",
    "\n",
    "Además, dividimos los datos en train (1993-2016) y test (2021-2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d865012-bed2-4eb6-a4e0-912b353d7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictando (Y) - ERA5-Land (Alta Resolución 0.1°)\n",
    "y_obs = readRDS('../../data/analogs/downscaling/tas_cgdds_ERA5-Land.rds')\n",
    "y_obs = subsetGrid(y_obs, season = c(4:8))\n",
    "yT_obs = subsetGrid(y_obs, years = 1993:2016)  # training\n",
    "yt_obs = subsetGrid(y_obs, years = 2021:2022)  # test\n",
    "\n",
    "# Predictores (X) - ERA5 (Resolución Original 0.25º - Interpolada a Resolución SEAS5 1º)\n",
    "x_sp = readRDS('../../data/analogs/downscaling/sp_ERA5.rds')\n",
    "x_sp = subsetGrid(x_sp, season = c(4:8))\n",
    "xT_sp = subsetGrid(x_sp, years = 1993:2016)  # training\n",
    "xt_sp = subsetGrid(x_sp, years = 2021:2022)  # test\n",
    "\n",
    "x_tas = readRDS('../../data/analogs/downscaling/tas_ERA5.rds')\n",
    "x_tas = subsetGrid(x_tas, season = c(4:8))\n",
    "xT_tas = subsetGrid(x_tas, years = 1993:2016)  # training\n",
    "xt_tas = subsetGrid(x_tas, years = 2021:2022)  # test\n",
    "\n",
    "# Unimos los grid con makeMultiGrid\n",
    "xT = makeMultiGrid(xT_tas, xT_sp)\n",
    "xt = makeMultiGrid(xt_tas, xt_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00db011-5c2f-4de5-a7e0-677db13422be",
   "metadata": {},
   "source": [
    "# Climatología de la temperatura de ERA5-Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6511c2d-0c11-44e4-9285-958a5e59d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor medio\n",
    "mean_ref = spatialPlot(climatology(yT_obs),\n",
    "                       backdrop.theme = \"countries\",\n",
    "                       main = \"Mean (train)\",\n",
    "                       col.regions = color) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "# Percentil 05\n",
    "p5_fun = function(x, ...) quantile(x, probs = 0.05, na.rm = TRUE)\n",
    "p5 = climatology(yT_obs, clim.fun = list(FUN = p5_fun, na.rm = TRUE)) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "p5_ref = spatialPlot(climatology(p5),\n",
    "                     backdrop.theme = \"countries\",\n",
    "                     main = \"P05 (train)\",\n",
    "                     col.regions = color) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "# Percentil 95\n",
    "p95_fun = function(x, ...) quantile(x, probs = 0.95, na.rm = TRUE)\n",
    "p95 = climatology(yT_obs, clim.fun = list(FUN = p95_fun, na.rm = TRUE)) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "p95_ref = spatialPlot(climatology(p95),\n",
    "                      backdrop.theme = \"countries\",\n",
    "                      main = \"P95 (train)\",\n",
    "                      col.regions = color) %>% suppressMessages %>% suppressWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c3c456-5502-4ca7-b667-c0db7e94157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "png(\"metricas_ERA5-Land.png\", width = 2000, height = 1000, res = 150)\n",
    "\n",
    "titulo_fila1 = textGrob(\"tas (ºC) ERA5-Land (0.1º)\",\n",
    "                        gp = gpar(fontsize = 18, fontface = \"bold\"))\n",
    "\n",
    "grid.arrange(titulo_fila1,\n",
    "             arrangeGrob(mean_ref, p5_ref, p95_ref, ncol = 3),\n",
    "             ncol = 1,\n",
    "             heights = c(0.1, 1))\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffe9b49-a672-46b6-bed5-de5e404b0adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media del grid (ºC):\n",
      " p5:  9.844189 \n",
      " p95:  26.95517 \n",
      " yT_obs:  19.34074 \n"
     ]
    }
   ],
   "source": [
    "# Media del grid para p5\n",
    "mean_p5 = mean(apply(p5$Data, c(2,3), function(x) mean(x, na.rm = TRUE)), na.rm = TRUE)\n",
    "\n",
    "# Media del grid para p95\n",
    "mean_p95 = mean(apply(p95$Data, c(2,3), function(x) mean(x, na.rm = TRUE)), na.rm = TRUE)\n",
    "\n",
    "# Media del grid para yT_obs\n",
    "mean_yT = mean(apply(yT_obs$Data, c(2,3), function(x) mean(x, na.rm = TRUE)), na.rm = TRUE)\n",
    "\n",
    "# Mostrar resultados\n",
    "cat(\"Media del grid (ºC):\\n\",\n",
    "    \"p5: \", mean_p5, \"\\n\",\n",
    "    \"p95: \", mean_p95, \"\\n\",\n",
    "    \"yT_obs: \", mean_yT, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ed254-f1d4-4be4-b2eb-1b81c5cb5ae3",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e35b7d-496d-4f6f-94e3-a7e6aca30c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-30 14:45:11.719507] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:45:14.096355] Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos (alineación temporal) y PCA de las variables combinadas reteniendo un 95% de la varianza\n",
    "data = prepareData(x = xT, y = yT_obs,\n",
    "                   spatial.predictors = list(\n",
    "                       v.exp = 0.95,\n",
    "                       which.combine = getVarNames(xT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02688ae5-f188-4dbd-b4b7-4cfd9c67c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entreno el modelo con los datos de train\n",
    "model = downscaleTrain(\n",
    "    obj = data,\n",
    "    method = \"analogs\", \n",
    "    n.analogs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621eb4f0-60ce-456d-a0cb-3bea827e29fb",
   "metadata": {},
   "source": [
    "# Model cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164fd8d2-06b1-4b48-abfe-b9ef45110d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fold: 1 --> calculating...\n",
      "\n",
      "[2025-12-30 14:47:01.293893] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:47:03.642204] Done.\n",
      "\n",
      "fold: 2 --> calculating...\n",
      "\n",
      "[2025-12-30 14:47:17.45861] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:47:19.813094] Done.\n",
      "\n",
      "fold: 3 --> calculating...\n",
      "\n",
      "[2025-12-30 14:47:33.377382] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:47:35.751133] Done.\n",
      "\n",
      "fold: 4 --> calculating...\n",
      "\n",
      "[2025-12-30 14:47:48.636781] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:47:50.997131] Done.\n",
      "\n",
      "fold: 5 --> calculating...\n",
      "\n",
      "[2025-12-30 14:48:03.998024] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:48:06.336886] Done.\n",
      "\n",
      "fold: 6 --> calculating...\n",
      "\n",
      "[2025-12-30 14:48:19.471467] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:48:21.833846] Done.\n",
      "\n",
      "fold: 7 --> calculating...\n",
      "\n",
      "[2025-12-30 14:48:35.062634] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:48:37.435724] Done.\n",
      "\n",
      "fold: 8 --> calculating...\n",
      "\n",
      "[2025-12-30 14:48:50.710601] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:48:53.111888] Done.\n",
      "\n",
      "fold: 9 --> calculating...\n",
      "\n",
      "[2025-12-30 14:49:06.48303] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:49:08.842134] Done.\n",
      "\n",
      "fold: 10 --> calculating...\n",
      "\n",
      "[2025-12-30 14:49:21.548079] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:49:23.922606] Done.\n",
      "\n",
      "fold: 11 --> calculating...\n",
      "\n",
      "[2025-12-30 14:49:36.837759] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:49:39.213287] Done.\n",
      "\n",
      "fold: 12 --> calculating...\n",
      "\n",
      "[2025-12-30 14:49:52.088352] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:49:54.390671] Done.\n",
      "\n",
      "fold: 13 --> calculating...\n",
      "\n",
      "[2025-12-30 14:50:07.357857] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:50:09.74254] Done.\n",
      "\n",
      "fold: 14 --> calculating...\n",
      "\n",
      "[2025-12-30 14:50:23.047636] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:50:25.403583] Done.\n",
      "\n",
      "fold: 15 --> calculating...\n",
      "\n",
      "[2025-12-30 14:50:38.537107] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:50:40.960814] Done.\n",
      "\n",
      "fold: 16 --> calculating...\n",
      "\n",
      "[2025-12-30 14:50:53.751099] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:50:56.22811] Done.\n",
      "\n",
      "fold: 17 --> calculating...\n",
      "\n",
      "[2025-12-30 14:51:09.467528] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:51:11.819934] Done.\n",
      "\n",
      "fold: 18 --> calculating...\n",
      "\n",
      "[2025-12-30 14:51:24.98041] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:51:27.328327] Done.\n",
      "\n",
      "fold: 19 --> calculating...\n",
      "\n",
      "[2025-12-30 14:51:40.151515] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:51:42.486766] Done.\n",
      "\n",
      "fold: 20 --> calculating...\n",
      "\n",
      "[2025-12-30 14:51:55.445482] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:51:57.845214] Done.\n",
      "\n",
      "fold: 21 --> calculating...\n",
      "\n",
      "[2025-12-30 14:52:10.995849] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:52:13.317466] Done.\n",
      "\n",
      "fold: 22 --> calculating...\n",
      "\n",
      "[2025-12-30 14:52:26.140314] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:52:28.512619] Done.\n",
      "\n",
      "fold: 23 --> calculating...\n",
      "\n",
      "[2025-12-30 14:52:41.482247] Performing PC analysis on 2 variables plus a combination ...\n",
      "\n",
      "[2025-12-30 14:52:43.903799] Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analog.cv = downscaleCV(x = xT, y = yT_obs, method = \"analogs\", n.analogs = 1,\n",
    "                        sampling.strategy = \"leave-one-year-out\",\n",
    "                        prepareData.args = list(\n",
    "                            spatial.predictors = list(which.combine = getVarNames(xT), v.exp = 0.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18410776-b812-44ea-ad45-57e01883945c",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828ce32-8da4-44d3-8288-d098cd3ea2ba",
   "metadata": {},
   "source": [
    "### Función auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b1d424-c5b4-4bfc-85b8-6a800c1173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular correlación de Pearson y valores p entre datos de modelo y observaciones en una grilla espacial\n",
    "# Además, identifica y marca los puntos con correlación estadísticamente significativa según un umbral de p-valor\n",
    "#\n",
    "# Args:\n",
    "#   model_data: objeto con datos del modelo, estructura esperada con dimensión [miembros, tiempo, latitud, longitud]\n",
    "#   obs_data: objeto con datos observacionales, estructura con dimensión [tiempo, latitud, longitud]\n",
    "#   ref_grid: objeto referencia con metadatos espaciales y temporales para construir grillas (xyCoords, Variable, Dates)\n",
    "#   threshold: umbral para marcar significancia estadística (p-valor), default 0.05\n",
    "#\n",
    "# Returns:\n",
    "#   Lista con:\n",
    "#     - cor: matriz de correlaciones [lat x lon]\n",
    "#     - pval: matriz de valores p [lat x lon]\n",
    "#     - pval_grid: objeto tipo \"grid\" con valores p y metadatos\n",
    "#     - pts: lista de objetos para graficar puntos de significancia (stippling)\n",
    "\n",
    "calc_cor_pval_grid = function(model_data, obs_data, ref_grid, threshold = 0.05) {\n",
    "    \n",
    "    # Dimensiones espaciales (latitud y longitud)\n",
    "    lat_n = dim(model_data$Data)[2]\n",
    "    lon_n = dim(model_data$Data)[3]\n",
    "  \n",
    "    # Inicializar matrices vacías para almacenar correlaciones y p-valores\n",
    "    cor_array = matrix(NA, nrow = lat_n, ncol = lon_n)\n",
    "    pval_array = matrix(NA, nrow = lat_n, ncol = lon_n)\n",
    "    \n",
    "    # Iterar sobre cada punto espacial\n",
    "    for (i in 1:lat_n) {\n",
    "        for (j in 1:lon_n) {\n",
    "            \n",
    "            # Extraer series temporales de modelo y observaciones para la celda actual\n",
    "            pred_series = model_data$Data[, i, j]\n",
    "            obs_series = obs_data$Data[, i, j]\n",
    "      \n",
    "            # Filtrar índices con datos completos (no NA)\n",
    "            valid_idx = complete.cases(pred_series, obs_series)\n",
    "            \n",
    "            # Solo calcular correlación si hay suficientes datos (mínimo 10)\n",
    "            if (sum(valid_idx) >= 10) {\n",
    "                test = cor.test(pred_series[valid_idx], obs_series[valid_idx], method = \"pearson\")\n",
    "                cor_array[i, j] = test$estimate  # Coeficiente de correlación\n",
    "                pval_array[i, j] = test$p.value  # Valor p de la prueba\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Construir un objeto \"grid\" para los valores p, con metadatos espaciales y temporales\n",
    "    pval_grid = list()\n",
    "    pval_grid$Data = pval_array\n",
    "    attr(pval_grid$Data, \"dimensions\") = c(\"lat\", \"lon\")\n",
    "    pval_grid$xyCoords = ref_grid$xyCoords\n",
    "    pval_grid$Variable = ref_grid$Variable\n",
    "    pval_grid$Dates = ref_grid$Dates\n",
    "    class(pval_grid) = \"grid\"\n",
    "\n",
    "    pval_grid$Variable$varName = \"p-values\"\n",
    "    attr(pval_grid$Variable, \"description\") = \"Mapa de p-valores\"\n",
    "    attr(pval_grid$Variable, \"units\") = \"\"\n",
    "    attr(pval_grid$Variable, \"longname\") = \"p-values\"\n",
    "\n",
    "    # Construir un objeto \"grid\" para los valores de correlación,\n",
    "    cor_grid = list()\n",
    "    cor_grid$Data = cor_array\n",
    "    attr(cor_grid$Data, \"dimensions\") = c(\"lat\", \"lon\")\n",
    "    cor_grid$xyCoords = ref_grid$xyCoords\n",
    "    cor_grid$Variable = ref_grid$Variable\n",
    "    cor_grid$Dates = ref_grid$Dates\n",
    "    class(cor_grid) = \"grid\"\n",
    "\n",
    "    cor_grid$Variable$varName = \"correlation\"\n",
    "    attr(cor_grid$Variable, \"description\") = \"Mapa de correlaciones\"\n",
    "    attr(cor_grid$Variable, \"units\") = \"\"\n",
    "    attr(cor_grid$Variable, \"longname\") = \"correlation\"\n",
    "\n",
    "    # Crear objetos para graficar puntos de significancia estadística (stippling)\n",
    "    pts = map.stippling(climatology(pval_grid), \n",
    "                        threshold = threshold, \n",
    "                        condition = \"LT\", \n",
    "                        pch = 19, col = \"black\", cex = 0.05) %>% suppressMessages() %>% suppressWarnings()\n",
    "    \n",
    "    # Devolver lista con resultados y objetos para plot\n",
    "    return(list(cor = cor_grid, pval = pval_array, pval_grid = pval_grid, pts = pts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69b1c5-340b-456b-bd25-db28eb4491c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Bias and corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c774c4b-56cb-4aa3-89b5-081e7c69c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el bias entre la predicción y las observaciones en el periodo de train para dos casos:\n",
    "# 1. Partición train sin CV\n",
    "# 2. Partición train con CV con leave-one-year-out\n",
    "ref = climatology(yT_obs) %>% suppressMessages %>% suppressWarnings\n",
    "diff = climatology(model$pred) %>% suppressMessages %>% suppressWarnings\n",
    "bias = gridArithmetics(diff, ref, operator = \"-\")\n",
    "b = spatialPlot(bias,\n",
    "                backdrop.theme = \"countries\",\n",
    "                main = \"Bias Train (Prediction - Obs)\",\n",
    "                col.regions = color,\n",
    "                at = seq(0, 0.3, 0.01))\n",
    "\n",
    "diff_cv = climatology(analog.cv) %>% suppressMessages %>% suppressWarnings\n",
    "bias_cv = gridArithmetics(diff_cv, ref, operator = \"-\")\n",
    "b_cv = spatialPlot(bias_cv,\n",
    "                   backdrop.theme = \"countries\",\n",
    "                   main = \"Bias Train CV (LOO) (Prediction - Obs)\",\n",
    "                   col.regions = color,\n",
    "                   at = seq(0, 0.3, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042164a5-6929-483b-9fb4-1664a8493c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo la correlación entre la predicción y las observaciones en el periodo de train para dos casos:\n",
    "# 1. Partición train sin CV\n",
    "# 2. Partición train con CV con leave-one-year-out\n",
    "test_cor = calc_cor_pval_grid(model$pred, yT_obs, model$pred)\n",
    "\n",
    "corr = spatialPlot(climatology(test_cor$cor),\n",
    "                   backdrop.theme = \"countries\",\n",
    "                   main = \"Corr Train\",\n",
    "                   sp.layout = list(test_cor$pts),\n",
    "                   col.regions = color,\n",
    "                   at = seq(-1, 1, 0.1)) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "test_cor_cv = calc_cor_pval_grid(analog.cv, yT_obs, analog.cv)\n",
    "\n",
    "corr_cv = spatialPlot(climatology(test_cor_cv$cor),\n",
    "                      backdrop.theme = \"countries\",\n",
    "                      main = \"Corr CV (LOO)\",\n",
    "                      sp.layout = list(test_cor_cv$pts),\n",
    "                      col.regions = color,\n",
    "                      at = seq(-1, 1, 0.1)) %>% suppressMessages %>% suppressWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746b878d-f59e-4536-93cc-4a5de24cb01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "png(\"metricas_train_comparison.png\", width = 2000, height = 1000, res = 150)\n",
    "\n",
    "titulo_fila1 = textGrob(\"Bias (Pred - Obs)\",\n",
    "                        gp = gpar(fontsize = 18, fontface = \"bold\"))\n",
    "\n",
    "titulo_fila2 = textGrob(\"Corr (Pred - Obs)\",\n",
    "                        gp = gpar(fontsize = 18, fontface = \"bold\"))\n",
    "\n",
    "grid.arrange(titulo_fila1,\n",
    "             arrangeGrob(b, b_cv, ncol = 2),\n",
    "             titulo_fila2,\n",
    "             arrangeGrob(corr, corr_cv, ncol = 2),\n",
    "             ncol = 1,\n",
    "             heights = c(0.1, 1, 0.1, 1))\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0532dde-f00f-43f0-8492-a925549b2ec1",
   "metadata": {},
   "source": [
    "# Predecimos sobre los datos de SEAS5 a 1º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e7abc9a-f316-49e7-a3f0-5079cca842a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo la tas de SEAS5 a 1º\n",
    "x_tas_seas5 = readRDS('../../data/analogs/downscaling/tas_cgdds_seas5_downscaling.rds')\n",
    "x_tas_seas5 = subsetGrid(x_tas_seas5, season = c(4:8))\n",
    "\n",
    "# Renombro variables para que coincidan con ERA5\n",
    "attr(x_tas_seas5$Variable, \"varName\") = \"t2m\"\n",
    "x_tas_seas5$Variable$varName = \"t2m\"\n",
    "\n",
    "# Subset temporal\n",
    "xT_tas_seas5 = subsetGrid(x_tas_seas5, years = 1993:2016)  # training\n",
    "xt_tas_seas5 = subsetGrid(x_tas_seas5, years = 2021:2022)  # test\n",
    "\n",
    "# Cargo la sp de CMCC\n",
    "x_sp_seas5 = readRDS('../../data/analogs/downscaling/sp_cmcc_downscaling.rds')\n",
    "x_sp_seas5 = subsetGrid(x_sp_seas5, season = c(4:8))\n",
    "\n",
    "# Renombro variables para que coincidan con ERA5\n",
    "attr(x_sp_seas5$Variable, \"varName\") = \"sp\"\n",
    "x_sp_seas5$Variable$varName = \"sp\"\n",
    "\n",
    "# Subset temporal\n",
    "xT_sp_seas5 = subsetGrid(x_sp_seas5, years = 1993:2016)  # training\n",
    "xt_sp_seas5 = subsetGrid(x_sp_seas5, years = 2021:2022)  # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88f69de6-2ed0-467d-a4f0-fd5135a628a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-30 14:53:39.473202] - Scaling by months ...\n",
      "\n",
      "[2025-12-30 14:53:58.947137] - Done\n",
      "\n",
      "[2025-12-30 14:53:58.949773] - Scaling by months ...\n",
      "\n",
      "[2025-12-30 14:54:19.708548] - Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estandarizamos los predictores del modelo por mes y gridbox\n",
    "xt_tas_harmonized = scaleGrid(grid = xt_tas_seas5,\n",
    "                              base = xT_tas_seas5,\n",
    "                              ref = xT_tas,\n",
    "                              type = \"center\",\n",
    "                              time.frame = \"monthly\",\n",
    "                              spatial.frame = \"gridbox\",\n",
    "                              by.member = FALSE)\n",
    "\n",
    "xt_sp_harmonized = scaleGrid(grid = xt_sp_seas5,\n",
    "                             base = xT_sp_seas5,\n",
    "                             ref = xT_sp,\n",
    "                             type = \"center\",\n",
    "                             time.frame = \"monthly\",\n",
    "                             spatial.frame = \"gridbox\",\n",
    "                             by.member = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c284891-88ce-4a87-b89d-61ac8372de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los grid con makeMultiGrid\n",
    "xt_seas5 = makeMultiGrid(xt_tas_harmonized, xt_sp_harmonized)\n",
    "\n",
    "# Preparo los nuevos datos de test\n",
    "newdata = prepareNewData(xt_seas5, data)\n",
    "\n",
    "# Predigo en test\n",
    "pred = downscalePredict(newdata, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a01b70b-ee28-420e-8bd8-1766cf8ad5e7",
   "metadata": {},
   "source": [
    "# Métricas predictando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307175c-ac36-4623-bafe-eee6ba19c271",
   "metadata": {},
   "source": [
    "Comparamos el valor de la temperatura del modelo habiendo hecho downscaling a 0.1º, con la temperatura original de ERA5-Land, ambas en el periodo de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88062767-358b-4816-b93a-d54f4bcefbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del RMSE\n",
    "bias = veriApply(verifun = \"EnsMe\", \n",
    "                 fcst = pred$Data, \n",
    "                 obs = yt_obs$Data, \n",
    "                 ensdim = 1, tdim = 2) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "# Reconstrucción del grid\n",
    "bias_grid = easyVeri2grid(easyVeri.mat = bias, obs.grid = yt_obs, verifun = \"EnsMe\")\n",
    "\n",
    "bias_pred = spatialPlot(climatology(bias_grid),\n",
    "                        backdrop.theme = \"countries\",\n",
    "                        col.regions = color,\n",
    "                        main = \"Bias (prediction)\") %>% suppressMessages %>% suppressWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a012e9c1-5777-40af-9bdc-78b3a017b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular correlación de Pearson y valores p entre datos de modelo y observaciones en una grilla espacial\n",
    "# Además, identifica y marca los puntos con correlación estadísticamente significativa según un umbral de p-valor\n",
    "#\n",
    "# Args:\n",
    "#   model_data: objeto con datos del modelo, estructura esperada con dimensión [miembros, tiempo, latitud, longitud]\n",
    "#   obs_data: objeto con datos observacionales, estructura con dimensión [tiempo, latitud, longitud]\n",
    "#   ref_grid: objeto referencia con metadatos espaciales y temporales para construir grillas (xyCoords, Variable, Dates)\n",
    "#   threshold: umbral para marcar significancia estadística (p-valor), default 0.05\n",
    "#\n",
    "# Returns:\n",
    "#   Lista con:\n",
    "#     - cor: matriz de correlaciones [lat x lon]\n",
    "#     - pval: matriz de valores p [lat x lon]\n",
    "#     - pval_grid: objeto tipo \"grid\" con valores p y metadatos\n",
    "#     - pts: lista de objetos para graficar puntos de significancia (stippling)\n",
    "\n",
    "calc_cor_pval_grid = function(model_data, obs_data, ref_grid, threshold = 0.05) {\n",
    "    \n",
    "    # Calcular la media del ensamble para cada punto [tiempo, lat, lon]\n",
    "    ens_mean = apply(model_data$Data, c(2, 3, 4), mean, na.rm = TRUE)\n",
    "    \n",
    "    # Dimensiones espaciales (latitud y longitud)\n",
    "    lat_n = dim(ens_mean)[2]\n",
    "    lon_n = dim(ens_mean)[3]\n",
    "  \n",
    "    # Inicializar matrices vacías para almacenar correlaciones y p-valores\n",
    "    cor_array = matrix(NA, nrow = lat_n, ncol = lon_n)\n",
    "    pval_array = matrix(NA, nrow = lat_n, ncol = lon_n)\n",
    "    \n",
    "    # Iterar sobre cada punto espacial\n",
    "    for (i in 1:lat_n) {\n",
    "        for (j in 1:lon_n) {\n",
    "            \n",
    "            # Extraer series temporales de modelo y observaciones para la celda actual\n",
    "            pred_series = ens_mean[, i, j]\n",
    "            obs_series = obs_data$Data[, i, j]\n",
    "      \n",
    "            # Filtrar índices con datos completos (no NA)\n",
    "            valid_idx = complete.cases(pred_series, obs_series)\n",
    "            \n",
    "            # Solo calcular correlación si hay suficientes datos (mínimo 10)\n",
    "            if (sum(valid_idx) >= 10) {\n",
    "                test = cor.test(pred_series[valid_idx], obs_series[valid_idx], method = \"pearson\")\n",
    "                cor_array[i, j] = test$estimate  # Coeficiente de correlación\n",
    "                pval_array[i, j] = test$p.value  # Valor p de la prueba\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Construir un objeto \"grid\" para los valores p, con metadatos espaciales y temporales\n",
    "    pval_grid = list()\n",
    "    pval_grid$Data = pval_array\n",
    "    attr(pval_grid$Data, \"dimensions\") = c(\"lat\", \"lon\")\n",
    "    pval_grid$xyCoords = ref_grid$xyCoords\n",
    "    pval_grid$Variable = ref_grid$Variable\n",
    "    pval_grid$Dates = ref_grid$Dates\n",
    "    class(pval_grid) = \"grid\"\n",
    "\n",
    "    pval_grid$Variable$varName = \"p-values\"\n",
    "    attr(pval_grid$Variable, \"description\") = \"Mapa de p-valores\"\n",
    "    attr(pval_grid$Variable, \"units\") = \"\"\n",
    "    attr(pval_grid$Variable, \"longname\") = \"p-values\"\n",
    "    \n",
    "    # Crear objetos para graficar puntos de significancia estadística (stippling)\n",
    "    pts = map.stippling(climatology(pval_grid), \n",
    "                        threshold = threshold, \n",
    "                        condition = \"LT\", \n",
    "                        pch = 19, col = \"black\", cex = 0.05) %>% suppressMessages() %>% suppressWarnings()\n",
    "    \n",
    "    # Devolver lista con resultados y objetos para plot\n",
    "    return(list(cor = cor_array, pval = pval_array, pval_grid = pval_grid, pts = pts))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ea856f-a704-4bca-9ad1-04172d6e7a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_cor = calc_cor_pval_grid(pred, yt_obs, pred)\n",
    "\n",
    "# Calculo del RMSE\n",
    "corr = veriApply(verifun = \"EnsCorr\", \n",
    "                 fcst = pred$Data, \n",
    "                 obs = yt_obs$Data, \n",
    "                 ensdim = 1, tdim = 2) %>% suppressMessages %>% suppressWarnings\n",
    "\n",
    "# Reconstrucción del grid\n",
    "corr_grid = easyVeri2grid(easyVeri.mat = corr, obs.grid = yt_obs, verifun = \"EnsCorr\")\n",
    "\n",
    "corr_pred = spatialPlot(climatology(corr_grid),\n",
    "                       backdrop.theme = \"countries\",\n",
    "                       sp.layout = list(test_cor$pts),\n",
    "                       col.regions = color,\n",
    "                       main = \"Corr (prediction)\",\n",
    "                       at = seq(-1, 1, 0.1)) %>% suppressMessages %>% suppressWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d9301f-b562-4001-8d24-61adb3676338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred = spatialPlot(climatology(pred, by.member = FALSE),\n",
    "                        backdrop.theme = \"countries\",\n",
    "                        main = \"Mean (prediction)\",\n",
    "                        col.regions = colorRampPalette(rev(brewer.pal(n = 9, \"RdYlBu\")))) %>% suppressMessages %>% suppressWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f32cb1f7-bd72-4c00-b8ad-65b2b36d462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "png(\"metricas_prediction.png\", width = 2000, height = 1000, res = 150)\n",
    "\n",
    "titulo_fila1 = textGrob(\"tas (ºC) SEAS5 downscaled (0.1º)\",\n",
    "                        gp = gpar(fontsize = 18, fontface = \"bold\"))\n",
    "\n",
    "grid.arrange(titulo_fila1,\n",
    "             arrangeGrob(mean_pred, bias_pred, corr_pred, ncol = 3),\n",
    "             ncol = 1,\n",
    "             heights = c(0.1, 1))\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02b033-e568-40d0-bf62-6baca37d0327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
